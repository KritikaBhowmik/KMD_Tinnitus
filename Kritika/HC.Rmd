---
title: "KMD"
author: "Kritika Bhowmik"
date: "6/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
First we would load all the necessary libraries
```{r}
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms
```
We now need to preprocess the data that we will use for creating hierarchical clusters
```{r}
#Data preprocessing
df <- read_rds("190426_charite_tinnitus.rds") %>%
  arrange(.testdatum) %>%
  group_by(.jour_nr) %>%
  slice(1) %>%
  ungroup() %>%
  filter(.phase == "A") %>%
  mutate(phqk_paniksyndrom = if_else(phqk_phqk_2a +
                                       phqk_phqk_2b +
                                       phqk_phqk_2c +
                                       phqk_phqk_2d +
                                       phqk_phqk_2e == 5, 1, 0)) %>%
  select(.jour_nr,
         .age,
         acsa_acsa,
         adsl_adsl_sum,
         bi_erschoepfung, bi_magen, bi_glieder, bi_herz, bi_beschwerden,
         bsf_geh, bsf_eng, bsf_aerg, bsf_an_de, bsf_mued, bsf_tnl,
         isr_deprsyn, isr_angstsyn, isr_zwasyn, isr_somasyn, isr_essstsyn,
         isr_zusatz, isr_isr_ges,
         phqk_depressivitaet, phqk_paniksyndrom,
         psq_anford, psq_anspan, psq_freude, psq_sorgen, psq_psq_sum,
         schmerzskal_beein10, schmerzskal_haeuf10, schmerzskal_staerke10,
         ses_ses_affektiv, ses_ses_sensorisch,
         sf8_bp_sf36ks, sf8_gh_sf36ag, sf8_mcs8, sf8_mh_sf36pw, sf8_pcs8,
         sf8_pf_sf36kf, sf8_re_sf36er, sf8_rp_sf36kr, sf8_sf_sf36sf, sf8_vt_sf36vit,
         sozk_soz01_male, sozk_soz02_german, sozk_soz05_partner, sozk_soz06_married,
         sozk_soz09_abitur, sozk_soz10_keinAbschl, sozk_soz11_job, sozk_soz18_selbstst, 
         sozk_soz1920_krank, sozk_soz21_tindauer, sozk_soz2224_psycho, sozk_soz25_numdoc,
         swop_sw, swop_opt, swop_pes,
         tq_aku, tq_co, tq_em, tq_inti, tq_pb, tq_sl, tq_som, tq_tf,
         tinskal_beein10, tinskal_haeuf10, tinskal_laut10,
         starts_with("tlq"), -tlq_timestamp
  ) %>%
  drop_na()
 df_scaled<-df%>%
  scale()  #for scaling/normalising the data
```
Hierarchical clustering can be done in two ways :
1) Top Down : Start with the entire data as a cluster and break them down until each point is a cluster in itself.
2) Bottom up : Start from individual points as clusters and merge them based on similarities until one cluster if formed.

There are different ways to calculate the distance/ similarity between individual points and in between the clusters which can be a very important factor in deciding the final cluster results.

So we first create a list of these methods and then create clusters for each combination.
```{r}
# methods to assess inter cluster similarity
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

#distance measures
dist_methods <- c("euclidean","manhattan","maximum", "canberra","binary","minkowski")
names(dist_methods)<- c("euclidean","manhattan","maximum", "canberra","binary","minkowski")

```

Now we can calculate the clusters. The ac value of each cluster gives the qulaity/ tightness of each cluster. The closer the value is to 1 the better are the results.

```{r}
# function to compute coefficient
final_dist_m<-list()
final_m<-list()
for(dist_m in dist_methods)
{
  dist_matrix<-dist(df_scaled, method = dist_m)
  for(x in m)
  {
    hc <-agnes(dist_matrix, method = x)
    ac<-hc$ac
    title<-sprintf("Distance: %s,Inter cluster Distance: %s, ac value: %f",dist_m,x,ac)
    pltree(hc, cex = 0.6, hang = -1,main = title)
    if(!is.nan(ac) && ac>0.95)
    {
      print(title)
      final_dist_m<-c(final_dist_m,dist_m)
      final_m<-c(final_m,x)
    }
  }
}
```

Now we can choose the desired combination, for example: Euclidean and Ward method and then we can cut the tree to get the final clusters.
```{r}

dist_matrix<-dist(df_scaled, method = "euclidean")
hc <-agnes(dist_matrix, method = "ward")
sub_group<-cutree(hc,k=4)
table(sub_group)
```
We can see above the number of records in each cluster.
Let us now label all our records with the respective cluster number.
```{r}
df_labeled<-df%>%
  mutate(label = sub_group)
df_labeled%>%head
```
